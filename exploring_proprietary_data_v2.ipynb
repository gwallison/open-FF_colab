{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f466238-ed44-4c6a-ae78-0f01525abe97",
   "metadata": {},
   "source": [
    "# Exploring data\n",
    "# Version 2\n",
    "\n",
    "Version 2 pulls data from a standard source and can be used for any bgCAS. (Although this is \n",
    "primarily designed to examine \"proprietary\" data).\n",
    "\n",
    "## Step 1: Get data into Colab\n",
    "Run the cells below to import Open-FF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b325c-96f6-431b-aef2-f3cc895882ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell downloads some support code that is used to pull together the data set.  \n",
    "!git clone https://github.com/gwallison/colab-support.git &>/dev/null;\n",
    "\n",
    "# now run the code that defines the routine\n",
    "%run colab-support/get_dataframe.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3153934e-ae2d-4c93-8d46-7d66f99fa951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_dataset pulls together a set of CSV files from a google storage site, then merges them\n",
    "#  result: df is a dataframe with all records (though not ALL fields)\n",
    "df = get_dataset()\n",
    "\n",
    "# if you want to see what fields are in df, uncomment the following line\n",
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b757e044-b8ae-4145-ac32-f95ac0b37c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to a single bgCAS type\n",
    "df_one = df[df.bgCAS=='proprietary'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80883b05-05c1-425c-bcf3-53d656c6ae8c",
   "metadata": {},
   "source": [
    "## Aggregating to a single value for each disclosure\n",
    "When there can be more than one record of a \"chemical\" in a disclosure and you want the total, you can aggregate to 'UploadKey', the unique value for each disclosure.  \n",
    "\n",
    "We use 'groupby' to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98ba41a-3c7f-4afd-a93b-afa802151f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb1 = df_one.groupby('UploadKey',as_index=False)[['calcMass','PercentHFJob']].sum()\n",
    "gb1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcc1f65-b49b-4e33-90ca-01e29a2f5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you want to add other fields to these sets, you need to do some other groupbys and then merge:\n",
    "# for these disclosure-wide fields, take just the first\n",
    "gb2 = df_one.groupby('UploadKey',as_index=False)[['APINumber','date','bgOperatorName','TotalBaseWaterVolume']].first()\n",
    "\n",
    "agg_df = pd.merge(gb1,gb2,on='UploadKey',how='left',validate='1:1')\n",
    "agg_df.head()\n",
    "\n",
    "# you can use this resulting aggregated df as your source data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e384ac-6306-4a04-8424-f4389c8cb930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de4e55a8-caef-42a9-8a48-37d8eb37622a",
   "metadata": {},
   "source": [
    "---\n",
    "# Proprietary area maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f420ffdc-da32-4c30-8b44-2449dcb51deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "\n",
    "def proprietary_plot(df,plot_title='TEST',minyr=2011,maxyr=2021):\n",
    "    df = df.copy()\n",
    "    df['year'] = df.date.dt.year\n",
    "    df = df[df.year<=maxyr]\n",
    "    df = df[df.year>=minyr]\n",
    "    \n",
    "    prop = df.bgCAS=='proprietary'\n",
    "    conflict = df.bgCAS=='conflictingID'\n",
    "    df['is_valid_CAS'] = prop | conflict | (df.bgCAS.str[0].isin(['0','1','2','3','4','5','6','7','8','9']))\n",
    "\n",
    "    # first get the number of proprietary records in each disclosure\n",
    "    gb = df[prop].groupby('UploadKey',as_index=False)['bgCAS'].count().rename({'bgCAS':'numprop'},axis=1)\n",
    "    # now get the total number of valid CAS records in each disclosure (this ignore ambiguous and system approach records)\n",
    "    gb1 = df[df.is_valid_CAS].groupby('UploadKey',as_index=False)['bgCAS'].count().rename({'bgCAS':'numvalid'},axis=1)\n",
    "    gb2 = df.groupby('UploadKey',as_index=False)['date'].first()\n",
    "    mg = pd.merge(gb2,gb,on='UploadKey',how='left')\n",
    "    mg = pd.merge(mg,gb1,on='UploadKey',how='left')\n",
    "    mg.fillna(0,inplace=True)\n",
    "    # make the Precent Proprietary field for each disclosure\n",
    "    mg['percProp'] = (mg.numprop / mg.numvalid) * 100\n",
    "\n",
    "    # cut it up into bins\n",
    "    mg['propCut'] = pd.cut(mg.percProp,right=False,bins=[0,0.0001,10,25,50,101],\n",
    "                          labels=['no proprietary claims','up to 10% proprietary claims',\n",
    "                                  'between 10 and 25% proprietary claims',\n",
    "                                  'between 25 and 50% proprietary claims',\n",
    "                                  'greater than 50% proprietary claims'])\n",
    "    mg['year'] = mg.date.dt.year\n",
    "    out = mg.drop(['date','UploadKey'],axis=1)\n",
    "    # summarize to year\n",
    "    t = out[out.numvalid>0].groupby(['year','propCut'],as_index=False)['numvalid'].count()\n",
    "    sums = t.groupby('year',as_index=False)['numvalid'].sum().rename({'numvalid':'tot'},axis=1)\n",
    "    t = pd.merge(t,sums,on='year',how='left')\n",
    "    # do the by-year calc\n",
    "    t['PercentProp'] = t.numvalid/t.tot *100\n",
    "\n",
    "    # pivot to make it easy to plot\n",
    "    piv = t.pivot(index='year', columns='propCut', values='PercentProp')\n",
    "\n",
    "    ax = piv.plot.area(figsize=(12,7),ylim=(0,100),xlim=(minyr,maxyr),colormap='Reds')\n",
    "    ax.set_title(f'Percentage of valid records that are Trade Secret claims at the disclosure level', fontsize=16)\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend(handles[::-1], labels[::-1], title='Disclosure Proprietary\\nPercentage class\\n',\n",
    "              loc='upper left',bbox_to_anchor=(1, 1))\n",
    "    ax.set_ylabel('Percentage of disclosures', fontsize=16)\n",
    "    ax.set_xlabel('Year', fontsize=16)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    plt.suptitle(f'{plot_title}',fontsize=24)\n",
    "\n",
    "    gb = df.groupby(['year','UploadKey'],as_index=False)['bgCAS'].count()\n",
    "    gb = gb.groupby('year',as_index=False)['UploadKey'].count()#.rename({'UploadKey':'number of disclosures'},axis=1)\n",
    "    s = 'Number of disclosures by year:\\n\\n'\n",
    "    for i,row in gb.iterrows():\n",
    "        s+= f'   {row.year}: {row.UploadKey:7,} \\n'\n",
    "    at2 = AnchoredText(s,\n",
    "                       loc='lower left', prop=dict(size=10), frameon=False,\n",
    "                       bbox_to_anchor=(1., 0.),\n",
    "                       bbox_transform=ax.transAxes\n",
    "                       )\n",
    "    at2.patch.set_boxstyle(\"square,pad=0.\")\n",
    "    ax.add_artist(at2)\n",
    "    \n",
    "proprietary_plot(df,'All data',minyr=2011,maxyr=2022)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
