{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a75320bb-dfb7-48f3-a1ad-bbc0e43bb108",
   "metadata": {},
   "source": [
    "# Making a data set for Oil and Gas Production in Montana\n",
    "\n",
    "## Task\n",
    "Combine and reformat 2 large files of Well information and Well production.\n",
    "\n",
    "## Technical issues encountered\n",
    "- Loading large files into Colab\n",
    "- Handling \"tab\" delimited data\n",
    "- Renaming columns\n",
    "- Summarizing monthly data to years \n",
    "- \"pivotting\" data to yearly columns\n",
    "- merging 2 data sets.\n",
    "\n",
    "## Result\n",
    "The product is a CSV file that is in a format needed at FracTracker.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6d7226-d1e9-4336-afb4-300a525e880c",
   "metadata": {},
   "source": [
    "## Reading files\n",
    "Two files are needed: \n",
    "- the first is the raw production values and is stored in a zip file on [Montana servers](http://www.bogc.dnrc.mt.gov/production/).  The code below will download that zipfile and extract the needed data.\n",
    "- the second is the well information and **you** will need to gather it from the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06786946-14fa-4126-9e03-1e8617e10c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile \n",
    "import requests\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c5dc89-f30f-4e8a-9d5c-6e6c6e76e1e2",
   "metadata": {},
   "source": [
    "### File 1: Download production zip file from Montana server\n",
    "Downloading this zipfile (over 140Mbyte) can take **two minutes or more** due to an apparently slow server in Montana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df4b841-d026-4155-bffc-804f5235c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an efficient routine to fetch a large file from a web address and save it\n",
    "# https://stackoverflow.com/a/39217788/6736072\n",
    "\n",
    "def download_file(url):\n",
    "    local_filename = url.split('/')[-1] # just names the local file like the last part of the link\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            shutil.copyfileobj(r.raw, f)\n",
    "    print(f'Downloaded {local_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f5a5b-675f-4876-aef7-9f195360787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zfn = 'http://www.bogc.dnrc.mt.gov/production/historical.zip'\n",
    "download_file(zfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cdde46-ea73-4fc7-89ea-a83f29eb3c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now pull the well production file into a dataframe\n",
    "# Note that in these \"read_csv\" functions, we set \"sep\" to  \" \\t \" which is a TAB character.\n",
    "\n",
    "with zipfile.ZipFile(zfn.split('/')[-1]) as z:\n",
    "    with z.open('histprodwell.tab') as f:\n",
    "        prod = pd.read_csv(f,sep='\\t',  # it is TAB delimited, not comma delimited\n",
    "                           low_memory=False,\n",
    "                           dtype={'API_WELLNO':'str'}) # we need to treat as a string not a number\n",
    "\n",
    "prod['year'] = pd.to_datetime(prod.rpt_date).dt.year # keep just the year\n",
    "\n",
    "# Keep only fields that we need. \n",
    "prod = prod[['API_WELLNO','BBLS_OIL_COND', 'MCF_GAS', 'BBLS_WTR', 'DAYS_PROD', 'year']]\n",
    "# rename them to something more useful\n",
    "prod.columns = ['APINumber','Oil', 'Gas', 'Water','Days','year']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba88e99c-c18c-4145-b9e8-5ec7ba7a7207",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Here is where we summarize by well and year\n",
    "gb = prod.groupby(['APINumber','year'],as_index=False)[['Oil', 'Gas', \n",
    "                                                        'Water','Days']].sum()\n",
    "gb.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad950b08-faa7-4eaa-a407-0142a36357b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe created above is \"long\":  each record has only one year \n",
    "# the code code below makes it \"wide\"; there is only one record per well ('APINumber')\n",
    "\n",
    "colnames = ['Oil','Gas','Water','Days']\n",
    "concat_list = []\n",
    "for col in colnames:\n",
    "    piv = gb.pivot(index='APINumber',columns='year',values=col).fillna(0)\n",
    "    names = piv.columns.tolist()\n",
    "    ncols = []\n",
    "    for name in names:\n",
    "        ncols.append(col+'_'+str(name))\n",
    "    piv.columns = ncols\n",
    "    piv[f'{col}_Total'] = piv.sum(axis=1)\n",
    "    concat_list.append(piv)\n",
    "\n",
    "whole = pd.concat(concat_list,axis=1)\n",
    "whole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efec689-5c5f-471f-ae6f-01ba49dd1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "piv.sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2db404-b458-431e-833e-c3c883bb2654",
   "metadata": {},
   "source": [
    "## File 2: Getting the well location data and uploading it to Colab\n",
    "This process takes a few manual steps.\n",
    "\n",
    "#### Step 1: Navigate to the Montana website\n",
    "Go to [this site](http://www.bogc.dnrc.mt.gov/webapps/dataminer/Wells/WellSurfaceLongLat.aspx).\n",
    "It should look something like:\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/montana_1.png\" height=100 />\n",
    "\n",
    "#### Step 2: Set up search for all wells\n",
    "1. Select \"API #\" in the first dropdown menu\n",
    "2. Type in \"25\" in the text box\n",
    "3. Click the search button\n",
    "\n",
    "<img src=\"images/montana_2.png\" height=100 />\n",
    "\n",
    "\n",
    "**The results should look something like this:**\n",
    "\n",
    "\n",
    "<img src=\"images/montana_3.png\" height=100 />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6121347-e940-4ad8-8f7e-26f421b93c79",
   "metadata": {},
   "source": [
    "#### Step 3: Save the results to your computer\n",
    "1. Click on the \"Text\" button in the upper right of the screen\n",
    "\n",
    "This will cause the website to display another page with LOTS of text.  It is actually a text file that is \"tab\" delimited (that is, the tab character separates the values in each row).\n",
    "\n",
    "2. Save the file to your computer.  Usually that means doing something simple like **Ctrl-s** and following the prompts. Save it with the file name \"Location.csv\".  (The code below uses that name. Change the code below if you want to name it something else.  Note that in Colab, names are case-sensitive.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0beaa1-c4e8-468b-804c-a48928bf9c90",
   "metadata": {},
   "source": [
    "#### Step 4: Move the file to Colab\n",
    "1. Back in the Colab window, open the \"Files\" panel on the far left by clicking on the folder icon (it may already be open).\n",
    "2. Click on the \"upload\" icon and follow the prompts to upload the file you saved in the last step.\n",
    "\n",
    "<img src=\"images/montana_4.png\" height=10 />\n",
    "\n",
    "**We can now clean up this file and merge it with the production file**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438b4147-263a-41d7-8a89-d39b7f0194a9",
   "metadata": {},
   "source": [
    "## Read the Location file into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4715a8df-6041-4537-822e-89a22bd2684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the location data comes directly from the commission's public website:\n",
    "# but note that we have saved the data using their \"text\" button and saved the file with a CSV extention.\n",
    "#   The data are TAB delimited.\n",
    "loc = pd.read_csv(\"Location.csv\",sep = '\\t')\n",
    "loc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83016433-3199-45f3-abab-2342b9d72801",
   "metadata": {},
   "source": [
    "## Cleanup names, merge, and save!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250929da-725e-44e3-a9e4-1c357b56b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc['APINumber'] = loc['API #'].str.replace('-','')\n",
    "loc.rename({'Wh_Long':'Longitude','Wh_Lat':'Latitude'},axis=1,inplace=True)\n",
    "out = pd.merge(loc[['APINumber','Longitude', 'Latitude']],whole,\n",
    "               on='APINumber',how='right',validate='1:1')\n",
    "\n",
    "out.to_csv('MT_prod_summary.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b035f7b7-e7d8-42d1-a70a-1ac387863714",
   "metadata": {},
   "source": [
    "## Spot check\n",
    "compare the pivot output table to the initial file (using sums across years) for a small subset of the data.  If something is screwy, this probably won't pass without errors.\n",
    "\n",
    "\n",
    "Takes about one minute to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfefebd2-1a1e-4bfd-9bf4-92ecf84a0ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = out.sample(n=20)  # get a random sample of the output dataframe\n",
    "#print(sample.head())\n",
    "types = ['Oil','Gas','Water','Days']\n",
    "for i,row in sample.iterrows():\n",
    "    api = row.APINumber\n",
    "    for ty in types:\n",
    "        initial = prod[prod.APINumber==api][ty].sum()\n",
    "        if row[f'{ty}_Total'] != initial:\n",
    "            print(f'Error in {ty} of {api}: {initial} vs. {row[f\"{ty}_Total\"]}')\n",
    "print('Spot check completed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
